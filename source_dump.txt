# ==================================================
# Path: D:\dow\doanfinal\projectfinal
# Detected tech: python
# ==================================================

## DIRECTORY STRUCTURE
```
projectfinal/
├── .git/
├── data/
│   ├── ctgan_generated_faults_by_type_with_time.csv
│   ├── full_dataset_with_gan.csv
│   ├── iot_equipment_monitoring_dataset.csv
│   ├── processed_ctgan_generated_faults.csv
│   └── processed_iot_dataset.csv
├── txl/
│   └── txl.py
├── generate_data_GAN.ipynb
├── train_and_predict_strategies.py
├── train_full_data_with_gan.py
├── train_normal_data.py
├── tuning_train_and_pre.py.py
├── tuning_train_full.py
└── visualization_GAN.ipynb
```

## FILE CONTENTS

### train_and_predict_strategies.py
```py
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import pairwise_distances

# ===== LOAD DATA =====
df_real = pd.read_csv("data/processed_iot_dataset.csv").dropna()
df_gan = pd.read_csv("data/processed_ctgan_generated_faults.csv").dropna()

features = ['Temperature', 'Vibration', 'Pressure', 'Voltage', 'Current',
            'FFT_Feature1', 'FFT_Feature2', 'Anomaly_Score']

df_real_faults = df_real[df_real['Fault_Status'] == 1].copy()
df_real_nonfaults = df_real[df_real['Fault_Status'] == 0].copy()

# ===== LỌC GAN THEO DISTANCE + ANOMALY =====
scaler = StandardScaler()
real_scaled = scaler.fit_transform(df_real_faults[features])
gan_scaled = scaler.transform(df_gan[features])
df_gan['distance'] = pairwise_distances(gan_scaled, real_scaled).min(axis=1)
df_gan_filtered = df_gan.copy()
df_gan_filtered['score'] = df_gan_filtered['distance'] - df_gan_filtered['Anomaly_Score']
df_gan_filtered = df_gan_filtered.sort_values('score')  # score thấp hơn → tốt hơn

# ===== DEFINE STRATEGIES =====
np.random.seed(42)
strategies = {
    # (1) Chỉ lỗi GAN
    "Chỉ lỗi GAN (5K+5K)": pd.concat([
        df_gan_filtered.head(5000),
        df_real_nonfaults.sample(5000)
    ], ignore_index=True),

    # (2) Lỗi GAN + lỗi thật
    "Lỗi GAN + Lỗi thật (2.5K+2.5K+5K)": pd.concat([
        df_gan_filtered.head(2500),
        df_real_faults.sample(2500),
        df_real_nonfaults.sample(5000)
    ], ignore_index=True),

    # (3) Chỉ lỗi thật (5K+5K)
    "Chỉ lỗi thật (5K+5K)": pd.concat([
        df_real_faults.sample(5000),
        df_real_nonfaults.sample(5000)
    ], ignore_index=True),

    # (4) Fine-tuning
    "Fine-tuned": None,  # xử lý riêng bên dưới
    # (5) Adaptive Ratio (3K+3K+4K)
    "Adaptive (3K+3K+4K)": pd.concat([
        df_gan_filtered.head(2500),
        df_real_faults.sample(2500),
        df_real_nonfaults.sample(5000)
    ], ignore_index=True),

    # (6) GAN Confidence (low distance + high anomaly)
    "GAN Confidence (Top 3K) + 2K + 5K": pd.concat([
        df_gan_filtered.head(3000),
        df_real_faults.sample(2000),
        df_real_nonfaults.sample(5000)
    ], ignore_index=True)
}

results = []

def train_and_evaluate(df, label):
    X = df[features]
    y = df['Fault_Status']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

    # Random Forest
    rf = RandomForestClassifier(random_state=42)
    rf.fit(X_train, y_train)
    pred_rf = rf.predict(X_test)
    f1_rf = f1_score(y_test, pred_rf)
    auc_rf = roc_auc_score(y_test, rf.predict_proba(X_test)[:, 1])
    print(f"\n=== Case: {label} - Random Forest ===")
    print("Confusion Matrix:\n", confusion_matrix(y_test, pred_rf))
    print(classification_report(y_test, pred_rf))
    print("ROC AUC:", auc_rf)
    results.append({"Case": label, "Model": "Random Forest", "F1": f1_rf, "AUC": auc_rf})

    # XGBoost
    xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
    xgb.fit(X_train, y_train)
    pred_xgb = xgb.predict(X_test)
    f1_xgb = f1_score(y_test, pred_xgb)
    auc_xgb = roc_auc_score(y_test, xgb.predict_proba(X_test)[:, 1])
    print(f"\n=== Case: {label} - XGBoost ===")
    print("Confusion Matrix:\n", confusion_matrix(y_test, pred_xgb))
    print(classification_report(y_test, pred_xgb))
    print("ROC AUC:", auc_xgb)
    results.append({"Case": label, "Model": "XGBoost", "F1": f1_xgb, "AUC": auc_xgb})

# ===== RUN STRATEGIES =====
for label, df_case in strategies.items():
    if label == "Fine-tuned":
        # Step 1: train on GAN
        df_gan_train = pd.concat([
            df_gan_filtered.head(5000),
            df_real_nonfaults.sample(5000)
        ], ignore_index=True)

        X1 = df_gan_train[features]
        y1 = df_gan_train['Fault_Status']
        model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
        model.fit(X1, y1)

        # Step 2: fine-tune on real faults
        df_real_ft = pd.concat([
            df_real_faults.sample(2500),
            df_real_nonfaults.sample(2500)
        ], ignore_index=True)
        X2 = df_real_ft[features]
        y2 = df_real_ft['Fault_Status']
        model.fit(X2, y2, xgb_model=model)  # fine-tuning

        # Step 3: test
        X_train, X_test, y_train, y_test = train_test_split(X2, y2, test_size=0.3, random_state=42)
        pred = model.predict(X_test)
        proba = model.predict_proba(X_test)[:, 1]
        f1 = f1_score(y_test, pred)
        auc = roc_auc_score(y_test, proba)

        print(f"\n=== Case: {label} - Fine-tuned XGBoost ===")
        print("Confusion Matrix:\n", confusion_matrix(y_test, pred))
        print(classification_report(y_test, pred))
        print(f"ROC AUC: {auc:.4f}")

        results.append({"Case": label, "Model": "XGBoost", "F1": f1, "AUC": auc})


    else:
        train_and_evaluate(df_case, label)

# ===== PLOT RESULTS =====
df_results = pd.DataFrame(results)
print(df_results)

plt.figure(figsize=(10, 5))
sns.barplot(data=df_results, x="Case", y="F1", hue="Model")
plt.title("So sánh F1-score giữa các chiến lược huấn luyện")
plt.xticks(rotation=25)
plt.tight_layout()
plt.show()

plt.figure(figsize=(10, 5))
sns.barplot(data=df_results, x="Case", y="AUC", hue="Model")
plt.title("So sánh AUC giữa các chiến lược huấn luyện")
plt.xticks(rotation=25)
plt.tight_layout()
plt.show()

```

### train_full_data_with_gan.py
```py
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score

# Load dữ liệu
df = pd.read_csv("data/full_dataset_with_gan.csv")
df = df.dropna()

# Cột đặc trưng và target
features = ['Temperature', 'Vibration', 'Pressure', 'Voltage', 'Current',
            'FFT_Feature1', 'FFT_Feature2', 'Anomaly_Score']
X = df[features]
y = df['Fault_Status']

# Chuẩn hóa
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Chia tập train-test
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.3, stratify=y, random_state=42)

# Huấn luyện Random Forest
rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)
roc_rf = roc_auc_score(y_test, rf.predict_proba(X_test)[:, 1])

print("=== Random Forest ===")
print(confusion_matrix(y_test, y_pred_rf))
print(classification_report(y_test, y_pred_rf))
print("ROC AUC:", roc_rf)

# Huấn luyện XGBoost
xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
xgb.fit(X_train, y_train)
y_pred_xgb = xgb.predict(X_test)
roc_xgb = roc_auc_score(y_test, xgb.predict_proba(X_test)[:, 1])

print("=== XGBoost ===")
print(confusion_matrix(y_test, y_pred_xgb))
print(classification_report(y_test, y_pred_xgb))
print("ROC AUC:", roc_xgb)

# Vẽ confusion matrix
fig, axs = plt.subplots(1, 2, figsize=(12, 5))
sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt="d", cmap="Blues", ax=axs[0])
axs[0].set_title("Random Forest")

sns.heatmap(confusion_matrix(y_test, y_pred_xgb), annot=True, fmt="d", cmap="Oranges", ax=axs[1])
axs[1].set_title("XGBoost")

plt.tight_layout()
plt.show()

```

### train_normal_data.py
```py
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score

# ===== 1. LOAD & PREPARE DATA =====
df = pd.read_csv("data/processed_iot_dataset.csv").dropna()

features = ['Temperature', 'Vibration', 'Pressure', 'Voltage', 'Current',
            'FFT_Feature1', 'FFT_Feature2', 'Anomaly_Score']
target = 'Fault_Status'

X = df[features]
y = df[target]

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.3, random_state=42, stratify=y
)

# ===== 2. EVALUATION FUNCTION =====
def evaluate_model(model, X_test, y_test, model_name="Model"):
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1]
    cm = confusion_matrix(y_test, y_pred)

    print(f"\n {model_name} ")
    print("Confusion Matrix:\n", cm)
    print("\nClassification Report:\n", classification_report(y_test, y_pred))
    print(f"ROC AUC: {roc_auc_score(y_test, y_proba):.4f}")

    plt.figure(figsize=(5, 4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(f'{model_name} - Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.tight_layout()
    plt.show()

# ===== 3. TRAIN & EVALUATE MODELS =====
# Random Forest
rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train)
evaluate_model(rf, X_test, y_test, model_name="Random Forest")

# XGBoost
xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
xgb.fit(X_train, y_train)
evaluate_model(xgb, X_test, y_test, model_name="XGBoost")

```

### tuning_train_and_pre.py.py
```py

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import pairwise_distances

# ==== Load & Preprocess ====
df_real = pd.read_csv("data/processed_iot_dataset.csv").dropna()
df_gan = pd.read_csv("data/processed_ctgan_generated_faults.csv").dropna()

features = ['Temperature', 'Vibration', 'Pressure', 'Voltage', 'Current',
            'FFT_Feature1', 'FFT_Feature2', 'Anomaly_Score']

df_real_faults = df_real[df_real['Fault_Status'] == 1].copy()
df_real_nonfaults = df_real[df_real['Fault_Status'] == 0].copy()

# ==== Filtering GAN Samples ====
scaler = StandardScaler()
real_scaled = scaler.fit_transform(df_real_faults[features])
gan_scaled = scaler.transform(df_gan[features])
df_gan['distance'] = pairwise_distances(gan_scaled, real_scaled).min(axis=1)
df_gan['score'] = df_gan['distance'] - df_gan['Anomaly_Score']
df_gan_filtered = df_gan.sort_values("score")

# ==== Define Training Strategies ====
np.random.seed(42)
strategies = {
    "Chỉ lỗi GAN (5K+5K)": pd.concat([
        df_gan_filtered.head(5000), 
        df_real_nonfaults.sample(5000)
        ], ignore_index=True),
    "Lỗi GAN + Lỗi thật (2.5K+2.5K+5K)": pd.concat([
        df_gan_filtered.head(2500), 
        df_real_faults.sample(2500), df_real_nonfaults.sample(5000)
        ], ignore_index=True),
    "Chỉ lỗi thật (5K+5K)": pd.concat([
        df_real_faults.sample(5000), 
        df_real_nonfaults.sample(5000)
        ], ignore_index=True),
    "Adaptive (3K+3K+4K)": pd.concat([
        df_gan_filtered.head(3000), 
        df_real_faults.sample(3000), 
        df_real_nonfaults.sample(4000)
        ], ignore_index=True),
    "GAN Confidence (Top 3K) + 2K + 5K": pd.concat([
        df_gan_filtered.head(3000), 
        df_real_faults.sample(2000), 
        df_real_nonfaults.sample(5000)
        ], ignore_index=True)
}

results = []

# ==== Tuning Function ====
def tune_model(X, y, model_type):
    if model_type == "Random Forest":
        model = RandomForestClassifier(random_state=42)
        params = {
            "n_estimators": [100, 200],
            "max_depth": [None, 10, 20],
            "min_samples_split": [2, 5]
        }
    else:
        model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
        params = {
            "n_estimators": [100, 200],
            "max_depth": [3, 6],
            "learning_rate": [0.1, 0.05]
        }

    grid = GridSearchCV(model, params, scoring='f1', cv=3, n_jobs=-1)
    grid.fit(X, y)
    return grid.best_estimator_

# ==== Training & Evaluation ====
def train_and_evaluate(df, label):
    X = df[features]
    y = df['Fault_Status']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

    for model_type in ["Random Forest", "XGBoost"]:
        best_model = tune_model(X_train, y_train, model_type)
        preds = best_model.predict(X_test)
        proba = best_model.predict_proba(X_test)[:, 1]
        f1 = f1_score(y_test, preds)
        auc = roc_auc_score(y_test, proba)
        print(f"\n=== Case: {label} - {model_type} ===")
        print("Confusion Matrix:\n", confusion_matrix(y_test, preds))
        print(classification_report(y_test, preds))
        print("ROC AUC:", auc)
        results.append({"Case": label, "Model": model_type, "F1": f1, "AUC": auc})

# ==== Run All Strategies ====
for label, df_case in strategies.items():
    train_and_evaluate(df_case, label)

# ==== Fine-tuning (XGBoost + Random Forest) ====
def run_fine_tuning():
    print("\nFine-tuned Models")
    gan_train = pd.concat([df_gan_filtered.head(5000), df_real_nonfaults.sample(5000)], ignore_index=True)
    real_finetune = pd.concat([df_real_faults.sample(2500), df_real_nonfaults.sample(2500)], ignore_index=True)

    X_gan, y_gan = gan_train[features], gan_train['Fault_Status']
    X_real, y_real = real_finetune[features], real_finetune['Fault_Status']
    X_train, X_test, y_train, y_test = train_test_split(X_real, y_real, test_size=0.3, random_state=42)

    # XGBoost Fine-tuned
    xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
    xgb.fit(X_gan, y_gan)
    xgb.fit(X_real, y_real, xgb_model=xgb)
    pred_xgb = xgb.predict(X_test)
    auc_xgb = roc_auc_score(y_test, xgb.predict_proba(X_test)[:, 1])
    f1_xgb = f1_score(y_test, pred_xgb)
    print("XGBoost Fine-tuned:")
    print(confusion_matrix(y_test, pred_xgb))
    print(classification_report(y_test, pred_xgb))
    print("ROC AUC:", auc_xgb)
    results.append({"Case": "Fine-tuned", "Model": "XGBoost", "F1": f1_xgb, "AUC": auc_xgb})

run_fine_tuning()

# ==== Visualization ====
df_results = pd.DataFrame(results)
print("\nKết quả tổng hợp:")
print(df_results)

order = ["Chỉ lỗi GAN (5K+5K)", "Lỗi GAN + Lỗi thật (2.5K+2.5K+5K)", "Chỉ lỗi thật (5K+5K)",
         "Fine-tuned", "Adaptive (3K+3K+4K)", "GAN Confidence (Top 3K) + 2K + 5K"]

plt.figure(figsize=(10, 5))
sns.barplot(data=df_results, x="Case", y="F1", hue="Model", order=order)
plt.title("So sánh F1-score giữa các chiến lược huấn luyện (Tuned)")
plt.xticks(rotation=25)
plt.tight_layout()
plt.show()

plt.figure(figsize=(10, 5))
sns.barplot(data=df_results, x="Case", y="AUC", hue="Model", order=order)
plt.title("So sánh AUC giữa các chiến lược huấn luyện (Tuned)")
plt.xticks(rotation=25)
plt.tight_layout()
plt.show()

```

### tuning_train_full.py
```py

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score

# ==== 1. Load & chuẩn hóa dữ liệu ====
df = pd.read_csv("data/full_dataset_with_gan.csv").dropna()

features = ['Temperature', 'Vibration', 'Pressure', 'Voltage', 'Current',
            'FFT_Feature1', 'FFT_Feature2', 'Anomaly_Score']
X = df[features]
y = df['Fault_Status']

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.3, stratify=y, random_state=42
)

# ==== 2. Hàm tuning với GridSearchCV ====
def tune_model(model_type):
    if model_type == "Random Forest":
        model = RandomForestClassifier(random_state=42)
        param_grid = {
            "n_estimators": [100, 200],
            "max_depth": [None, 10, 20],
            "min_samples_split": [2, 5]
        }
    else:  # XGBoost
        model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
        param_grid = {
            "n_estimators": [100, 200],
            "max_depth": [3, 6],
            "learning_rate": [0.05, 0.1]
        }

    grid = GridSearchCV(model, param_grid, scoring='f1', cv=2, n_jobs=-1)
    grid.fit(X_train, y_train)
    print(f" Best params for {model_type}: {grid.best_params_}")
    return grid.best_estimator_

# ==== 3. Huấn luyện & đánh giá ====
def evaluate_model(model, X_test, y_test, name):
    y_pred = model.predict(X_test)
    proba = model.predict_proba(X_test)[:, 1]
    auc = roc_auc_score(y_test, proba)
    print(f"\n {name}")
    print(confusion_matrix(y_test, y_pred))
    print(classification_report(y_test, y_pred))
    print(f"ROC AUC: {auc:.4f}")
    return y_pred

# Random Forest (Tuned)
best_rf = tune_model("Random Forest")
y_pred_rf = evaluate_model(best_rf, X_test, y_test, "Random Forest (Tuned)")

# XGBoost (Tuned)
best_xgb = tune_model("XGBoost")
y_pred_xgb = evaluate_model(best_xgb, X_test, y_test, "XGBoost (Tuned)")

# ==== 4. Vẽ confusion matrix ====
fig, axs = plt.subplots(1, 2, figsize=(12, 5))
sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt="d", cmap="Blues", ax=axs[0])
axs[0].set_title("Random Forest (Tuned)")

sns.heatmap(confusion_matrix(y_test, y_pred_xgb), annot=True, fmt="d", cmap="Oranges", ax=axs[1])
axs[1].set_title("XGBoost (Tuned)")

plt.tight_layout()
plt.show()

```

### txl\txl.py
```py
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
import os

# Đọc dữ liệu
file_path = os.path.join('D:/dow/test1/txl/data/iot_equipment_monitoring_dataset.csv')
df = pd.read_csv(file_path)

# Hiển thị thông tin tổng quan về dữ liệu
print("Thông tin dữ liệu:")
print(df.info())
print("\nSố lượng giá trị bị thiếu trong mỗi cột:")
print(df.isnull().sum())

# Chuyển Timestamp về datetime và tách thành các cột con
df['Timestamp'] = pd.to_datetime(df['Timestamp'])
df['Year'] = df['Timestamp'].dt.year
df['Month'] = df['Timestamp'].dt.month
df['Day'] = df['Timestamp'].dt.day
df['Hour'] = df['Timestamp'].dt.hour
df['Minute'] = df['Timestamp'].dt.minute
df.drop(columns=['Timestamp'], inplace=True)

# Đưa cột thời gian lên đầu
time_columns = ['Day', 'Month', 'Year', 'Hour', 'Minute']
other_columns = [col for col in df.columns if col not in time_columns]
df = df[time_columns + other_columns]

# Mã hóa Sensor_ID (bỏ tiền tố 'S')
if 'Sensor_ID' in df.columns:
    df['Sensor_ID'] = df['Sensor_ID'].astype(str).str.extract('(\d+)').astype(int)

# Xoá các cột đã chuẩn hóa sẵn
columns_to_drop = ['Normalized_Temp', 'Normalized_Vibration', 'Normalized_Pressure', 'Normalized_Voltage', 'Normalized_Current']
df.drop(columns=[col for col in columns_to_drop if col in df.columns], inplace=True)

# Mã hóa Fault_Type
# Mã hóa trực tiếp cột Fault_Type
fault_type_mapping = {'Normal': 0, 'Electrical Fault': 1, 'Mechanical Failure': 2, 'Overheating': 3}
df['Fault_Type'] = df['Fault_Type'].fillna('Normal').map(fault_type_mapping)

# df['Fault_Type'] = df['Fault_Type'].fillna('Normal')
# fault_type_mapping = {'Normal': 0, 'Electrical Fault': 1, 'Mechanical Failure': 2, 'Overheating': 3}
# df['Fault_Type_Encoded'] = df['Fault_Type'].map(fault_type_mapping)

# # Kiểm tra và loại bỏ cột object không cần thiết
# for col in df.select_dtypes(include=['object']).columns:
#     print(f"Cột '{col}' có dữ liệu không phải số -> loại bỏ.")
#     df.drop(columns=[col], inplace=True)

# Chuẩn hóa dữ liệu
features = ['Temperature', 'Vibration', 'Pressure', 'Voltage', 'Current']
scaler = MinMaxScaler()
df[features] = scaler.fit_transform(df[features])

# Vẽ Boxplot để xem ngoại lai
sensor_columns = ['Temperature', 'Vibration', 'Pressure', 'Voltage', 'Current']

plt.figure(figsize=(12, 8))
for i, col in enumerate(sensor_columns):
    plt.subplot(2, 3, i + 1)
    sns.boxplot(data=df, x=col)
    plt.title(f'Box Plot - {col}')
plt.tight_layout()
plt.show()


# Hàm xử lý outlier bằng IQR
def remove_outliers_iqr(df, columns):
    df_clean = df.copy()
    for column in columns:
        Q1 = df_clean[column].quantile(0.25)
        Q3 = df_clean[column].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        df_clean = df_clean[(df_clean[column] >= lower_bound) & (df_clean[column] <= upper_bound)]
    return df_clean

# Áp dụng loại bỏ outlier cho các cột cảm biến gốc
sensor_columns = ['Temperature', 'Vibration', 'Pressure', 'Voltage', 'Current']
df_no_outliers = remove_outliers_iqr(df, sensor_columns)
print(f"\nKích thước dữ liệu sau khi loại bỏ outliers: {df_no_outliers.shape}")

# Trực quan phân phối Fault_Status
print("\nPhân phối dữ liệu (Fault_Status):")
print(df['Fault_Status'].value_counts())
imbalance_ratio = df['Fault_Status'].value_counts(normalize=True)
print("\nTỷ lệ mất cân bằng dữ liệu:")
print(imbalance_ratio)

plt.figure(figsize=(10, 6))
sns.countplot(x='Fault_Status', data=df)
plt.title("Sự mất cân bằng dữ liệu trong cột Fault_Status")
plt.xlabel("Fault_Status")
plt.ylabel("Số lượng")
plt.show()

# Trực quan hóa phân phối loại lỗi
plt.figure(figsize=(10, 6))
sns.countplot(x='Fault_Type', data=df)
plt.title('Phân phối các loại lỗi')
plt.xlabel('Fault Type (0: Normal, 1: Electrical, 2: Mechanical, 3: Overheating)')
plt.ylabel('Số lượng')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Ma trận tương quan
plt.figure(figsize=(10, 8))
corr_matrix = df.corr()
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', cbar=True)
plt.title('Ma trận tương quan')
plt.show()

# Lưu dữ liệu đã xử lý
processed_file_path = os.path.join('D:/dow/test1/txl/data/processed_iot_dataset.csv')
df.to_csv(processed_file_path, index=False)
print("Đã lưu file processed_iot_dataset.csv thành công!")

```
